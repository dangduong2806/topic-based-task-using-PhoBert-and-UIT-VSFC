import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix
import yaml
from src.datamodules.uit_vsfc_module import UITVSFCDataModule
from src.models.phobert_module import PhoBERTClassifier


# Giáº£ sá»­ 'model' lÃ  model PhoBERT cá»§a báº¡n Ä‘Ã£ load checkpoint tá»‘t nháº¥t
# Giáº£ sá»­ 'test_loader' lÃ  dá»¯ liá»‡u test cá»§a báº¡n

def evaluate_and_report(model, data_loader, device):
    model.eval()
    model.to(device)
    
    all_preds = []
    all_labels = []
    
    print("Äang cháº¡y Ä‘Ã¡nh giÃ¡...")
    with torch.no_grad():
        for batch in data_loader:
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)
            
            outputs = model(input_ids, attention_mask, labels=None)
            _, preds = torch.max(outputs.logits, dim=1)
            
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
    
    # 1. In BÃ¡o cÃ¡o chi tiáº¿t (Classification Report)
    # ÄÃ¢y chÃ­nh lÃ  cÃ¡i báº£ng giá»‘ng há»‡t áº£nh máº«u báº¡n thÃ­ch
    target_names = ['Lecturer', 'Curriculum', 'Facility', 'Others']
    report = classification_report(all_labels, all_preds, target_names=target_names, digits=4)
    print("\n--- Káº¾T QUáº¢ CHI TIáº¾T (Standard Report) ---")
    print(report)
    
    # 2. Váº½ Ma tráº­n nháº§m láº«n (Confusion Matrix)
    cm = confusion_matrix(all_labels, all_preds)
    
    plt.figure(figsize=(10, 8))
    # Váº½ heatmap mÃ u xanh
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=target_names, yticklabels=target_names)
    plt.xlabel('Dá»± Ä‘oÃ¡n (Predicted)')
    plt.ylabel('Thá»±c táº¿ (Actual)')
    plt.title('Confusion Matrix')

    # THAY DÃ’NG plt.show() Báº°NG DÃ’NG DÆ¯á»šI ÄÃ‚Y:
    plt.savefig('confusion_matrix.png') 
    print("âœ… ÄÃ£ lÆ°u áº£nh ma tráº­n nháº§m láº«n vÃ o file: confusion_matrix.png")
    
    # Náº¿u muá»‘n cháº¯c Äƒn thÃ¬ in luÃ´n text ra
    print("\n--- MA TRáº¬N NHáº¦M LáºªN (Dáº NG Sá») ---")
    print(cm)

# --- CÃCH Gá»ŒI HÃ€M ---
if __name__ == "__main__":
    config_path = "configs/config.yaml"
    with open(config_path, "r") as f:
        cfg = yaml.safe_load(f)

    dm = UITVSFCDataModule(
        data_dir=cfg['data']['data_dir'],
        model_name=cfg['model']['model_name'],
        batch_size=cfg['data']['batch_size'],
        max_len=cfg['data']['max_len'],
        num_workers=cfg['data']['num_workers']
    )
    dm.setup(stage="test")
    test_loader = dm.test_dataloader()
    if len(test_loader) == 0:
        print("Lá»—i Ä‘Æ°á»ng dáº«n")
    print("\nğŸ”¥ DEBUG KIá»‚M TRA Dá»® LIá»†U THá»°C Táº¾ ğŸ”¥")
    # Láº¥y 1 batch Ä‘áº§u tiÃªn ra soi
    batch = next(iter(test_loader))
    input_ids = batch['input_ids']
    labels = batch['labels']

    # 1. Kiá»ƒm tra Label
    print(f"Labels (3 máº«u Ä‘áº§u): {labels[:3].cpu().numpy()}")

    # 2. Quan trá»ng nháº¥t: GIáº¢I MÃƒ Láº I TEXT XEM CÃ“ Dáº¤U Gáº CH Ná»I KHÃ”NG?
    # DÃ¹ng chÃ­nh tokenizer cá»§a dm Ä‘á»ƒ decode
    decoded_text = dm.tokenizer.decode(input_ids[0], skip_special_tokens=True)
    print(f"ğŸ‘‰ Text máº«u 1 model nhÃ¬n tháº¥y: '{decoded_text}'")

    if "_" in decoded_text:
        print("âœ… Text CÃ“ chá»©a dáº¥u gáº¡ch ná»‘i (Data chuáº©n Segmented).")
    else:
        print("âŒ Cáº¢NH BÃO: Text KHÃ”NG cÃ³ dáº¥u gáº¡ch ná»‘i! (Model Ä‘ang Ä‘á»c data thÃ´)")
        
    print("------------------------------------------\n")
    # Load model
    checkpoint_path = "checkpoints/model2.ckpt"
    print(f"Äang load model tá»«: {checkpoint_path}")
    model = PhoBERTClassifier.load_from_checkpoint(checkpoint_path)
    model.eval()
    model.freeze()
    print("âœ… ÄÃ£ load model thÃ nh cÃ´ng! Sáºµn sÃ ng Ä‘á»ƒ dá»± Ä‘oÃ¡n.")

    evaluate_and_report(model, test_loader, device='cuda')